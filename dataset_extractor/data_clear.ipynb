{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ae8ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall -y sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c85a5add",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow-gpu in /home/user/conda/lib/python3.7/site-packages (2.3.0)\n",
      "Collecting tensorflow-gpu\n",
      "  Using cached tensorflow_gpu-2.7.0-cp37-cp37m-manylinux2010_x86_64.whl (489.6 MB)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/jovyan/.local/lib/python3.7/site-packages (from tensorflow-gpu) (3.3.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/jovyan/.local/lib/python3.7/site-packages (from tensorflow-gpu) (1.1.0)\n",
      "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /home/jovyan/.local/lib/python3.7/site-packages (from tensorflow-gpu) (1.12)\n",
      "Requirement already satisfied: tensorboard~=2.6 in /home/jovyan/.local/lib/python3.7/site-packages (from tensorflow-gpu) (2.6.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/jovyan/.local/lib/python3.7/site-packages (from tensorflow-gpu) (1.39.0)\n",
      "Collecting tensorflow-estimator<2.8,~=2.7.0rc0\n",
      "  Using cached tensorflow_estimator-2.7.0-py2.py3-none-any.whl (463 kB)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /home/jovyan/.local/lib/python3.7/site-packages (from tensorflow-gpu) (1.1.2)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/user/conda/lib/python3.7/site-packages (from tensorflow-gpu) (4.0.1)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /home/user/conda/lib/python3.7/site-packages (from tensorflow-gpu) (3.19.1)\n",
      "Requirement already satisfied: numpy>=1.14.5 in /home/user/conda/lib/python3.7/site-packages (from tensorflow-gpu) (1.18.5)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.21.0\n",
      "  Using cached tensorflow_io_gcs_filesystem-0.23.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.1 MB)\n",
      "Requirement already satisfied: gast<0.5.0,>=0.2.1 in /home/user/conda/lib/python3.7/site-packages (from tensorflow-gpu) (0.3.3)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /home/user/conda/lib/python3.7/site-packages (from tensorflow-gpu) (2.10.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/user/conda/lib/python3.7/site-packages (from tensorflow-gpu) (1.16.0)\n",
      "Requirement already satisfied: keras<2.8,>=2.7.0rc0 in /home/user/conda/lib/python3.7/site-packages (from tensorflow-gpu) (2.7.0)\n",
      "Requirement already satisfied: absl-py>=0.4.0 in /home/user/conda/lib/python3.7/site-packages (from tensorflow-gpu) (1.0.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/jovyan/.local/lib/python3.7/site-packages (from tensorflow-gpu) (1.6.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.32.0 in /home/jovyan/.imgenv-gpu-inst8-0/lib/python3.7/site-packages (from tensorflow-gpu) (0.37.0)\n",
      "Collecting libclang>=9.0.1\n",
      "  Using cached libclang-12.0.0-py2.py3-none-manylinux1_x86_64.whl (13.4 MB)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/jovyan/.local/lib/python3.7/site-packages (from tensorflow-gpu) (0.2.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/jovyan/.local/lib/python3.7/site-packages (from tensorflow-gpu) (1.12.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/user/conda/lib/python3.7/site-packages (from tensorboard~=2.6->tensorflow-gpu) (0.4.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/jovyan/.local/lib/python3.7/site-packages (from tensorboard~=2.6->tensorflow-gpu) (0.6.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/user/conda/lib/python3.7/site-packages (from tensorboard~=2.6->tensorflow-gpu) (2.26.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/user/conda/lib/python3.7/site-packages (from tensorboard~=2.6->tensorflow-gpu) (1.8.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/user/conda/lib/python3.7/site-packages (from tensorboard~=2.6->tensorflow-gpu) (3.3.6)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /home/user/conda/lib/python3.7/site-packages (from tensorboard~=2.6->tensorflow-gpu) (1.35.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/user/conda/lib/python3.7/site-packages (from tensorboard~=2.6->tensorflow-gpu) (2.0.2)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /home/jovyan/.imgenv-gpu-inst8-0/lib/python3.7/site-packages (from tensorboard~=2.6->tensorflow-gpu) (59.4.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /home/user/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow-gpu) (4.2.4)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/user/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow-gpu) (4.7.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/user/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow-gpu) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/user/conda/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow-gpu) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /home/user/conda/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow-gpu) (4.8.2)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/user/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow-gpu) (2.0.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/user/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow-gpu) (3.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/user/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow-gpu) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/user/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow-gpu) (2021.10.8)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/user/conda/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow-gpu) (3.6.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/user/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow-gpu) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/user/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow-gpu) (3.1.1)\n",
      "Installing collected packages: tensorflow-io-gcs-filesystem, tensorflow-estimator, libclang, tensorflow-gpu\n",
      "  Attempting uninstall: tensorflow-estimator\n",
      "    Found existing installation: tensorflow-estimator 2.3.0\n",
      "    Uninstalling tensorflow-estimator-2.3.0:\n",
      "      Successfully uninstalled tensorflow-estimator-2.3.0\n",
      "  Attempting uninstall: tensorflow-gpu\n",
      "    Found existing installation: tensorflow-gpu 2.3.0\n",
      "    Uninstalling tensorflow-gpu-2.3.0:\n",
      "      Successfully uninstalled tensorflow-gpu-2.3.0\n",
      "Successfully installed libclang-12.0.0 tensorflow-estimator-2.7.0 tensorflow-gpu-2.7.0 tensorflow-io-gcs-filesystem-0.23.1\n",
      "Collecting tensorflow-hub\n",
      "  Using cached tensorflow_hub-0.12.0-py2.py3-none-any.whl (108 kB)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in /home/user/conda/lib/python3.7/site-packages (from tensorflow-hub) (3.19.1)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /home/user/conda/lib/python3.7/site-packages (from tensorflow-hub) (1.18.5)\n",
      "Installing collected packages: tensorflow-hub\n",
      "Successfully installed tensorflow-hub-0.12.0\n"
     ]
    }
   ],
   "source": [
    "!pip3 install --upgrade tensorflow-gpu\n",
    "# Install TF-Hub.\n",
    "!pip3 install tensorflow-hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "062ac913",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3179a42",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-25 17:10:12.248645: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow_hub'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_91183/2227532442.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow_hub\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mhub\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmodule_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"https://tfhub.dev/google/universal-sentence-encoder/4\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"module %s loaded\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mmodule_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow_hub'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "module_url = \"https://tfhub.dev/google/universal-sentence-encoder/4\" \n",
    "model = hub.load(module_url)\n",
    "print (\"module %s loaded\" % module_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ceea5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_dataset = \"SSORC_CS_2010_2021\" #\"SSORC_Philosophy_2000_2021\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66fdec57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/conda/lib/python3.7/site-packages/numpy/lib/arraysetops.py:569: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "papers_features = pd.read_csv(\"processed_data/\" + global_dataset + \"_papers_features.csv\", index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "693667bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "papers_edges = pd.read_csv(\"processed_data/\" + global_dataset + \"_papers_edge_list.csv\", index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77a553d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "authors_edges = pd.read_csv(\"processed_data/\" + global_dataset + \"_authors_edge_list.csv\", index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "19d32c01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>from</th>\n",
       "      <th>to</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1404113169</td>\n",
       "      <td>2064312724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1404113169</td>\n",
       "      <td>1419382500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1404113169</td>\n",
       "      <td>2365393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1404113169</td>\n",
       "      <td>143638168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1404113169</td>\n",
       "      <td>1693033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30796744</th>\n",
       "      <td>101883681</td>\n",
       "      <td>143937657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30796745</th>\n",
       "      <td>101883681</td>\n",
       "      <td>9904205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30796746</th>\n",
       "      <td>101883681</td>\n",
       "      <td>145414870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30796747</th>\n",
       "      <td>143937657</td>\n",
       "      <td>9904205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30796748</th>\n",
       "      <td>143937657</td>\n",
       "      <td>145414870</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30796749 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                from          to\n",
       "0         1404113169  2064312724\n",
       "1         1404113169  1419382500\n",
       "2         1404113169     2365393\n",
       "3         1404113169   143638168\n",
       "4         1404113169     1693033\n",
       "...              ...         ...\n",
       "30796744   101883681   143937657\n",
       "30796745   101883681     9904205\n",
       "30796746   101883681   145414870\n",
       "30796747   143937657     9904205\n",
       "30796748   143937657   145414870\n",
       "\n",
       "[30796749 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "authors_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3fa273b",
   "metadata": {},
   "outputs": [],
   "source": [
    "authors_papers = pd.read_csv(\"processed_data/\" + global_dataset + \"_authors_edges_papers.csv\", index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "73f8aaca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          984774e366d3d4fcf0fce659f697478dccd4f93c\n",
       "1          8f604e61182948798ddee8ed11791017271f40d8\n",
       "2          8e52ecee2bbaeb80d5ab9a11849476e86997e89d\n",
       "3          f0eed1fe1e047de11e6a8e01862138b26200b6ce\n",
       "4          1d1b4025f4029c99d5f87f1750b71044a137e181\n",
       "                             ...                   \n",
       "2682704    6be5b43a54dcf7b5b5799d8e79b178ba32fa143a\n",
       "2682705    5ba1672d78b8a80bba82189222b22640181e01f4\n",
       "2682706    dc42b2bec435fad0b1e66172c434edc03ff1c419\n",
       "2682707    faa494fc680d79110a975bb35cba72b2ed5ebd77\n",
       "2682708    071c7bd3edf07fb5d80eb4b11078a172f0359651\n",
       "Name: id, Length: 2682709, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29fe9a4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2682709/2682709 [00:27<00:00, 97576.30it/s] \n"
     ]
    }
   ],
   "source": [
    "papers_id = papers_features[\"id\"]\n",
    "id_to_index_id = {papers_id[i]:i for i in tqdm(range(len(papers_id)))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d0d0209",
   "metadata": {},
   "outputs": [],
   "source": [
    "authors_papers_unzipped = authors_papers[\"papers_ids\"].map(lambda x: x.replace(\"[\", \"\").replace(\"]\", \"\").replace(\"'\", \"\").split(\", \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a0039434",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30796749/30796749 [14:19<00:00, 35835.00it/s] \n"
     ]
    }
   ],
   "source": [
    "authors_papers_indexed = [[id_to_index_id[authors_papers_unzipped[i][j]] for j in range(len(authors_papers_unzipped[i]))] for i in tqdm(range(len(authors_papers_unzipped)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1c619420",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30796749/30796749 [00:17<00:00, 1772642.16it/s]\n"
     ]
    }
   ],
   "source": [
    "authors_papers_indexed_str = [str(authors_papers_indexed[i]) for i in tqdm(range(len(authors_papers_indexed)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f36e8d36",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                  [984774e366d3d4fcf0fce659f697478dccd4f93c]\n",
       "1                  [984774e366d3d4fcf0fce659f697478dccd4f93c]\n",
       "2           [984774e366d3d4fcf0fce659f697478dccd4f93c, fdd...\n",
       "3           [984774e366d3d4fcf0fce659f697478dccd4f93c, fdd...\n",
       "4           [984774e366d3d4fcf0fce659f697478dccd4f93c, fdd...\n",
       "                                  ...                        \n",
       "30796744           [071c7bd3edf07fb5d80eb4b11078a172f0359651]\n",
       "30796745           [071c7bd3edf07fb5d80eb4b11078a172f0359651]\n",
       "30796746           [071c7bd3edf07fb5d80eb4b11078a172f0359651]\n",
       "30796747           [071c7bd3edf07fb5d80eb4b11078a172f0359651]\n",
       "30796748           [071c7bd3edf07fb5d80eb4b11078a172f0359651]\n",
       "Name: papers_ids, Length: 30796749, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "authors_papers_unzipped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1bd9fc82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'f0eed1fe1e047de11e6a8e01862138b26200b6ce'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers_id[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ec396d63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_to_index_id['f0eed1fe1e047de11e6a8e01862138b26200b6ce']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a6dde388",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(authors_papers_indexed_str, columns = [\"papers_indices\"]).to_csv(\"processed_data/\" + global_dataset + \"_authors_edges_papers_indices.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e280df20",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = papers_features[papers_features[['id', 'title', 'paperAbstract', 'year', 'journalName', 'fieldsOfStudy']].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c20f132",
   "metadata": {},
   "outputs": [],
   "source": [
    "papers_features_abstracts = list(papers_features[\"paperAbstract\"])\n",
    "papers_features_abstracts = [str(papers_features_abstracts[i]) for i in range(len(papers_features_abstracts))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cfbfe8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "papers_features[\"paperAbstract\"] = papers_features[\"paperAbstract\"].fillna(\"No abstract provided\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ed0f6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d2297e20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Load Balancing plays a dynamic role in keeping the tempo of the Cloud Computing framework. This research paper proposes a Forest Optimization Algorithm for load balancing in distributed computing structure. This depends on the conduct of the trees in the forest and uses the seed dispersal strategies for streamlining the makespan, which results in improved average response time and the total execution time. The simulation results prove that the proposed algorithm gives better outcomes than its counterpart load balancing algorithms.',\n",
       " 'nan',\n",
       " 'The classical concept lattices express the precise relation between object sets and attribute sets, but fuzzy concept lattices express the uncertain relation between object sets and attribute sets. Therefore, it is important to study hierarchy fuzzy knowledge from a fuzzy formal context. In this paper, a kind of fuzzy decision formal context is proposed and (α, β) reduct based on this fuzzy decision formal context is defined. Furthermore, we propose a method to judge attribute consistent sets and reducts in fuzzy decision formal contexts. Finally, a Boolean method is also formulated to attribute reduction in fuzzy decision formal context from the view of the discernibility matrix.',\n",
       " 'This paper shows how a particular resiliency-centered approach to chance lends support for two conditions characterizing chance. The first condition says that the present chance of some proposition A conditional on the proposition about some later chance of A should be set equal to that later chance of A. The second condition requires the present chance of some proposition A to be equal to the weighted average of possible later chances of A. I first introduce, motivate, and make precise a resiliency-centered approach to chance whose basic idea is that any chance distribution should be maximally invariant under variation of experimental factors. Second, I show that any present chance distribution that violates the two conditions can be replaced by another present chance distribution that satisfies them and is more resilient under variation of experimental factors. This shows that the two conditions are an essential feature of chances that maximize resiliency. Finally, I explore the relationship between the idea of resilient chances so understood and so-called Humean accounts of chance—one of the most promising recent philosophical accounts of chance.',\n",
       " 'Interconnection of different access network technologies is an important research topic in mobile telecommunications systems. In this paper, we propose an ns-3 architecture for simulating the interconnection of wireless local area network (WLAN) and Universal Mobile Telecommunications System (UMTS). This architecture is based on the architecture proposed by the Third Generation Partnership Project, being the use of virtual interfaces as its main innovation. In order to demonstrate the value of the proposed simulation framework, we implemented the UMTS and WLAN interconnection considering three joint radio resource management strategies for distributing arriving calls. From the simulations results, we can conclude that the proposed simulation architecture is suitable to test and evaluate performance aspects related to the interconnection and joint management of UMTS and WLAN technologies. Copyright © 2012 John Wiley & Sons, Ltd.',\n",
       " 'This paper presents a new method for steplength selection in the frame of spectral gradient methods. The steplength formula is based on the interpolation scheme as well as some modified secant equations. The corresponding algorithm selects the initial positive steplength per iteration according to the satisfaction of the secant condition, and then a backtracking procedure along the negative gradient is performed.The numerical experience shows that this algorithm improves favorably the efficiency property of the standard Barzilai–Borwein method as well as some other recently modified Barzilai–Borwein approaches.',\n",
       " \"This paper addresses a family of issues surrounding the biological phenomenon of resistance and its representation in realist ontologies. The treatments of resistance terms in various existing ontologies are examined and found to be either overly narrow, internally inconsistent, or otherwise problematic. We propose a more coherent characterization of resistance in terms of what we shall call blocking dispositions, which are collections of mutually coordinated dispositions which are of such a sort that they cannot undergo simultaneous realization within a single bearer. A definition of 'protective resistance' is proposed for use in the Infectious Disease Ontology (IDO) and we show how this definition can be used to characterize the antibiotic resistance in Methicillin-Resistant Staphylococcus aureus (MRSA). The ontological relations between entities in our MRSA case study are used alongside a series of logical inference rules to illustrate logical reasoning about resistance. A description logic representation of blocking dispositions is also provided. We demonstrate that our characterization of resistance is sufficiently general to cover two other cases of resistance in the infectious disease domain involving HIV and malaria.\",\n",
       " 'In this paper, we provide a simple framework to derive and analyse a class of one-step methods that may be conceived as a generalization of the class of Gauss methods. The framework consists in coupling two simple tools: firstly a local Fourier expansion of the continuous problem is truncated after a finite number of terms and secondly the coefficients of the expansion are computed by a suitable quadrature formula. Different choices of the basis lead to different classes of methods, even though we shall here consider only the case of an orthonormal polynomial basis, from which a large subclass of Runge–Kutta methods can be derived. The obtained results are then applied to prove, in a simplified way, the order and stability properties of Hamiltonian BVMs (HBVMs), a recently introduced class of energy preserving methods for canonical Hamiltonian systems (see [2] and references therein). A few numerical tests are also included, in order to confirm the effectiveness of the methods resulting from our analysis.',\n",
       " \"The transmit beamforming for millimeter wave systems has become a promising strategy to achieve higher spectral efficiency. The beamforming design for such systems stems out from various network optimization criterions that strike a balance between quality of service and energy/cost incurred to the system. We offer a simple and comprehensive solution to one of such key network optimization problems, namely transmit power minimization in multi-user millimeter wave system constrained on users' desired quality of service. The minimum transmit power beamforming vector is designed via hybrid analog and digital precoder that satisfies the practical hardware constraints. The crux of simplicity of the proposed algorithm lies in the fact that the analog beamforming could be solved via equal gain transmission method and the digital beamforming via zero forcing and Perron-Frobenius theorem. We also present simulation results of the proposed algorithms illustrating the performance gain comparable to computationally expensive fully digital and unconstrained beamforming algorithms.\",\n",
       " 'Abstract This paper presents an output feedback tracking control scheme for a three-wheeled omnidirectional mobile robot, based on passivity property and a modified generalized proportional integral (GPI) observer. The proposed control approach is attractive from an implementation point of view, since only one robot geometrical parameter (i.e., contact radius) is required. Firstly, a nominal dynamic model is given and the passivity property is analyzed. Then the controller is designed based on passivity property and a modified GPI observer. The controller design objective is to preserve the passivity property of the robot system in the closed-loop system, which is conceptually different from the traditional model-based control methodology. Particularly, the designed control system takes full advantage of the robot natural damping. Therefore, only considerably small or non differential feedback is needed. In addition, theoretical analysis is given to show the closed-loop stability behavior. Finally, experiments are conducted to validate the effectiveness of the proposed control system design in both tracking and robustness performance.',\n",
       " 'With recent advances in radio-frequency identification (RFID), wireless sensor networks, and Web services, physical things are becoming an integral part of the emerging ubiquitous Web. Correlation discovery for ubiquitous things is critical for many important applications such as things search, recommendation, annotation, classification, clustering, composition, and management. In this paper, we propose a novel approach for discovering things correlation based on user, temporal, and spatial information captured from usage events of things. In particular, we use a spatio-temporal graph and a social graph to model things usage contextual information and user-thing relationships respectively. Then, we apply random walks with restart on these graphs to compute correlations among things. This correlation analysis lays a solid foundation and contributes to improved effectiveness in things management. To demonstrate the utility of our approach, we perform a systematic case study and comprehensive experiments on things annotation.',\n",
       " 'This demonstration presents a complete software framework for dynamically mapping multi-threaded applications on a cycle accurate Network-on-Chip (NoC) architecture, analyzing the statistics of network workloads and drawing general guidelines regarding the design and optimization of NoCs.',\n",
       " 'A uniformly second order method with a local solver based on the piecewise linear discontinuous Galerkin formulation is introduced to solve the eikonal equation with Dirichlet boundary conditions. The method utilizes an interesting phenomenon, referred as the superconvergence phenomenon, that the numerical solution of monotone upwind schemes for the eikonal equation is first order accurate on both its value and gradient when the solution is smooth. This phenomenon greatly simplifies the local solver based on the discontinuous Galerkin formulation by reducing its local degrees of freedom from two (1-D) (or three (2-D), or four (3-D)) to one with the information of the gradient frozen. When considering the eikonal equation with point-source conditions, we further utilize a factorization approach to resolve the source singularities of the eikonal by decomposing it into two parts, either multiplicatively or additively. One part is known and captures the source singularities; the other part serves as a correction term that is differentiable at the sources and satisfies the factored eikonal equations. We extend the second order method to solve the factored eikonal equations to compute the correction term with second order accuracy, then recover the eikonal with second order accuracy. Numerical examples are presented to demonstrate the performance of the method.',\n",
       " 'Transfer of training is \"transferring\" the knowledge and skills acquired by instructors in training sessions applied to the workplace. Hence, this study aims to look at the views and agreements of experts on the need for elements of transfer of technical and vocational trainers training. This study is a quantitative study. The approach used to collect the research data is to use a questionnaire instrument that will be given to the expert. The number of experts involved is 13 experts. There are two criteria in the expert\\'s determination, that they are comprised of business management lecturers who have served more than 15 years and have been directly involved with the final teaching of the final project course. All data collected were analyzed using Fuzzy Delphi Method. The findings show that all training transfer elements consisting of training designs, the threshold value is less than 0.2 and the percentage of expert groups is over 75%. This shows that the design elements of the training and all the items contained therein are required by the Vocational College business management instructors based on expert agreement.',\n",
       " \"In screening decisions, senior managers from various disciplines need to collaborate to evaluate innovation project proposals and decide about the allocation of scarce resources to selected projects. Screening decisions are complex and made under high levels of uncertainty, and are considered to be one of senior management's most challenging tasks. In the present field study, screening decision making is investigated from the perspective of a Transactive Memory System (TMS). TMS theory explains how cross-disciplinary groups of people in interdependent relationships gain, store, combine, and utilize their knowledge in solving complex problems. According to this theory, a TMS emerges to the extent that team members manage to synchronize three core socio-cognitive processes - specialization, building credibility, and coordination - to achieve team objectives. A theoretical model summarizing antecedents and consequences of the emergence of a TMS in a screening context is proposed and investigated using structural equation modeling. Data from 136 screening committees were used. Results show that the degree to which a committee acts as a TMS is positively related to decision-making effectiveness as well as efficiency in a screening context. Transformational leadership and an open organizational climate are shown to act as antecedents of TMS emergence. Theoretical and managerial implications of these findings are discussed. © 2012 Product Development & Management Association.\",\n",
       " 'Building energy management is a major topic of research and development, as well as, buildings constitute the substantial amount of energy consumption in the worldwide. Design of an automated controller for energy efficiency operation in the building is one of the main methods to reduce energy consumption by keeping comfort level for inhabitants. In this paper, we introduce an alternative way to save energy by using fuzzy logic based approach. Fuzzy logic has been widely used to simulate energy consumption model and to control heating, ventilation and humidifying devices. Simulation results illustrate the behavior relation of whole system and each control parameter.',\n",
       " 'Abstract In this paper, we propose a new method for denoising the volumetric magnetic resonance (MR) images degraded with Rician noise. Taking into account the multi-frame (multi-linear) nature, the proposed method formulates an unsophisticated approach by contemplating the MR data as third order tensor. Since the Rician noise is signal dependent, variance stabilization technique (VST) is applied to transform it as additive noise. The cubic patches extracted from 3D MR images are grouped as tensors which exhibit low-rank property. Thus, denoising problem is modelled as a low-rank tensor approximation of grouped tensors, solved by minimizing the tensor nuclear norm (TNN) in tensor-singular value decomposition (t-SVD) framework. Each denoised tensors are weighted-averaged to obtain the final denoised data. The efficiency of proposed algorithm is compared with the state of art techniques and has exhibited substantial improvement in terms of quality metrics such as PSNR, SSIM and EPI for synthetic MR images. The algorithm performance is assessed for real MR images with no reference quality metric viz. sharpness index (SI) and have shown superior results. Moreover, the effectiveness of proposed algorithm for MR image segmentation is evaluated. As observed from results, the accuracy of segmentation with regards to kappa coefficient is improved by 1–5% after applying the proposed denoising algorithm.',\n",
       " 'We study the degrees of freedom (DoF) of MIMO two-way X relay channels. Previous work studied the case N <; 2M, where N and M denote the number of antennas at the relay and each source, respectively, and showed that the maximum DoF of 2N is achievable when N <; ⌊8M/5⌋ by applying signal alignment (SA) for network coding and interference cancelation. This work considers the case N > 2M where the performance is limited by the number of antennas at each source node and conventional SA is not feasible. We propose a generalized signal alignment (GSA) based transmission scheme. The key is to let the signals to be exchanged between every source node align in a transformed subspace, rather than the direct subspace, at the relay so as to form network-coded signals. This is realized by jointly designing the precoding matrices at all source nodes and the processing matrix at the relay. Moreover, the aligned subspaces are orthogonal to each other. By applying the GSA, we show that the DoF upper bound 4M is achievable when M ≤ ⌊ 2N/5 ⌋ (M is even) or M ≤ ⌊ 2N-1 /5 ⌋ (M is odd). Numerical results also demonstrate that our proposed transmission scheme is feasible and effective.',\n",
       " 'Efficient image sequence coding exploits both intra- and inter-frame correlations. Set partition coding (SPC) is efficient in intra-frame de-correlation for still images. Based on SPC, a novel image sequence coding system, called motion differential SPC (M-D-SPC), is presented in this paper. It removes inter-frame redundancy by re-using the significance map of a previously SPC coded frame. Every frame is encoded and decoded separate from other frames. Furthermore, there is no reconstruction of encoded frames in the encoder, as is done with interframe prediction methods. The M-D-SPC exhibits an auxiliary key frame coding framework, which achieves higher coding efficiency compared to the all-intra-coding schemes and meanwhile maintains the beneficial features of SPC all-intra-coding, such as computational simplicity, rate scalability, error non-propagation, and random frame access. SPIHT-based simulations on hyperspectral images, 3D/4D medical images, and video show greater compression efficiency than the standard intraframe coding method of motion JPEG2000.',\n",
       " 'In this paper, we study the source mobility problem that exists in the current named data networking (NDN) architecture and propose a proxy-based mobility support approach named PMNDN to overcome the problem. PMNDN proposes using a proxy to efficiently manage source mobility. Besides, functionalities of the NDN access routers are extended to track the mobility status of a source and signal Proxy about a handoff event. With this design, a mobile source does not need to participate in handoff signaling which reduces the consumption of limited wireless bandwidth. PMNDN also features an ID that is structurally similar to the content name so that routing scalability of NDN architecture is maintained and addressing efficiency of Interest packets is improved. We illustrate the performance advantages of our proposed solution by comparing the handoff performance of the mobility support approaches with that in NDN architecture and current Internet architecture via analytical and simulation investigation. We show that PMNDN offers lower handoff cost, shorter handoff latency, and less packet losses during the handoff process.',\n",
       " 'In this paper, a numerical technique for the computation of polynomial chaos expansion coefficients pertaining to the per-unit-length parameters of cable lines with random cross-sectional parameters is implemented and employed to create stochastic and SPICE-compatible circuit models. According to the principles of the polynomial chaos-based simulation, statistical information on the cable response is obtained via a single circuit simulation, thus being much faster compared to traditional sampling-based techniques.',\n",
       " 'Abstract ‘Big’ high-dimensional data are commonly analyzed in low-dimensions, after performing a dimensionality reduction step that inherently distorts the data structure. For a similar analysis, clustering methods are also often used. These methods introduce a bias as well, either by starting from the assumption of a particular, often geometric, property of the clusters, or by using iterative schemes to enhance cluster contours, with consequences that are hard to control. The goal of data analysis should, however, be to encode and detect structural data features at all scales and densities simultaneously, without assuming a parametric form of data point distances, or modifying them. Here, we propose a novel approach that directly encodes data point neighborhood similarities as a sparse graph. Our non-iterative framework permits a transparent interpretation of data, without altering the original data dimension and metric. Several natural and synthetic data applications demonstrate the efficacy of our novel method.',\n",
       " 'Entanglement for the eigenvectors of a nonlinear eigenvalue problem given by the Kronecker product of the Pauli spin matrices is investigated. Fully and partially entangled eigenvectors are found.',\n",
       " 'Most thin-film transistor (TFT) gate drivers integrated on the display panel use the carry signals between the stages. In our previous works, we found that these carry-type gate drivers are subject to the reliability problem in a flexible display, since the errors of the stressed stages are accumulated through the carry signals. This problem possibly leads to the failure of image refresh of the display device. Therefore, the carry-free gate driver can resolve the error accumulation problem since it does not use the carry signals and instead, each unit stage operates independently. In this paper, we propose an advanced carry-free gate driver circuit to remove the drawbacks of the previous version, while keeping the advantages. More importantly, this paper is the first report to experimentally show that the error accumulation phenomenon of the carry-type gate driver and the problem is removed in the carry-free gate driver. The proposed carry-free gate driver and the carry-type gate driver are fabricated with amorphous indium-gallium-zinc-oxide TFTs on a flexible substrate for comparison purpose. The proposed gate driver shows a very high reliability since no voltage fluctuation occurs at the outputs after 10 000 cycles bending test with 2-mm bending radius.',\n",
       " 'Abstract Biologists have mostly studied under what circumstances honest signaling is stable. Stability, however, is not sufficient to explain the emergence of honest signaling. We study the evolution of honest signaling between selfish, adaptive individuals and observe that honest signaling can emerge through learning. More importantly, honest signaling may emerge in cases where it is not evolutionary stable. In such cases, honesty and dishonesty co-exist. Furthermore, honest signaling does not necessarily emerge in cases where it is evolutionary stable. We show that the latter is due to the existence of other, more important equilibria and that the importance of equilibria is related to Pareto-optimality.',\n",
       " 'Automatic vision-based defect detection on the mobile light guide plate (LGP) is a challenging task due to the low contrast between the defect and the background, uneven brightness, and complex gradient texture. An end-to-end multitask learning network architecture for the defect detection of mobile phone LGP is proposed. First, the main structure of the multitask learning network is designed. The encoder part uses a similar U-Net encoder structure to obtain multiscale features, and the feature fusion part adopts feature fusion to interact with multiscale features. Second, the segmentation head is designed to complete the precise location of each defect in an image by using the multiscale feature fusion, which prepares it for the quantification of defect characteristics. Combining the multiscale features and the output mask of the segmentation head, the classification head is designed to accurately detect the defects of mobile phone LGP. Finally, the defect detection data set has been constructed based on the mobile phone LGP images collected on the industrial site, and a lot of experiments are performed on the mobile phone LGP data set and Kolektor surface-defect data set (KolektorSDD). The experimental results show that the F1-score on the two data sets can reach 99.67% and 96.77%, respectively, which verifies the effectiveness of the method proposed in this article.',\n",
       " 'Matrix factorization is useful to extract the essential low-rank structure from a given matrix and has been paid increasing attention. A typical example is non-negative matrix factorization (NMF), which is one type of unsupervised learning, having been successfully applied to a variety of data including documents, images and gene expression, where their values are usually non-negative. We propose a new model of NMF which is trained by using auxiliary information of overlapping groups. This setting is very reasonable in many applications, a typical example being gene function estimation where functional gene groups are heavily overlapped with each other. To estimate true groups from given overlapping groups efficiently, our model incorporates latent matrices with the regularization term using a mixed norm. This regularization term allows group-wise sparsity on the optimized low-rank structure. The latent matrices and other parameters are efficiently estimated by a block coordinate gradient descent method. We empirically evaluated the performance of our proposed model and algorithm from a variety of viewpoints, comparing with four methods including MMF for auxiliary graph information, by using both synthetic and real world document and gene expression data sets.',\n",
       " 'In this paper, we propose a model for mobile application profiles, wireless interfaces, and cloud resources. First, an algorithm to allocate wireless interfaces and cloud resources has been introduced. The proposed model is based on the wireless network cloud (WNC) concept. Then, considering power consumption, application quality of service (QoS) profiles, and corresponding cost functions, a multi-objective optimization approach using an event-based finite state model and dynamic constraint programming method has been used to determine the appropriate transmission power, process power, cloud offloading and optimum QoS profiles. Numerical results show that the proposed algorithm saves the mobile battery life and guarantees both QoS and cost simultaneously. Moreover, it determines the best available cloud server resources and wireless interfaces for applications at the same time.']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers_features_abstracts[2322:2350]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc21abff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1c499551",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2682709/2682709 [1:45:57<00:00, 421.95it/s]\n"
     ]
    }
   ],
   "source": [
    "vectorized_abstracts = []\n",
    "for i in tqdm(range(len(papers_features_abstracts))):\n",
    "    abstract = papers_features_abstracts[i]\n",
    "    vectorized_abstracts.append(model([abstract])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2b59f8f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2682709/2682709 [00:12<00:00, 218287.87it/s]\n"
     ]
    }
   ],
   "source": [
    "vectorized_abstracts_list = [vectorized_abstracts[i].numpy() for i in tqdm(range(len(vectorized_abstracts)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c6d3902c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized_abstracts_df = pd.DataFrame(vectorized_abstracts_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d654ea90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "print(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8bcd0e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized_abstracts_df.to_csv(\"processed_data/\" + global_dataset + \"_papers_features_vectorized_512.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8fe2c8e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>502</th>\n",
       "      <th>503</th>\n",
       "      <th>504</th>\n",
       "      <th>505</th>\n",
       "      <th>506</th>\n",
       "      <th>507</th>\n",
       "      <th>508</th>\n",
       "      <th>509</th>\n",
       "      <th>510</th>\n",
       "      <th>511</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.059651</td>\n",
       "      <td>-0.058564</td>\n",
       "      <td>-0.043585</td>\n",
       "      <td>-0.055376</td>\n",
       "      <td>0.040285</td>\n",
       "      <td>-0.059395</td>\n",
       "      <td>0.042767</td>\n",
       "      <td>0.054109</td>\n",
       "      <td>-0.033267</td>\n",
       "      <td>0.060300</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010115</td>\n",
       "      <td>-0.060441</td>\n",
       "      <td>-0.005488</td>\n",
       "      <td>-0.058637</td>\n",
       "      <td>0.028976</td>\n",
       "      <td>0.057778</td>\n",
       "      <td>-0.015628</td>\n",
       "      <td>0.060211</td>\n",
       "      <td>-0.057778</td>\n",
       "      <td>-0.060236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.020976</td>\n",
       "      <td>-0.016075</td>\n",
       "      <td>-0.021127</td>\n",
       "      <td>-0.066995</td>\n",
       "      <td>-0.012023</td>\n",
       "      <td>-0.006514</td>\n",
       "      <td>-0.045765</td>\n",
       "      <td>-0.060472</td>\n",
       "      <td>0.070335</td>\n",
       "      <td>0.057117</td>\n",
       "      <td>...</td>\n",
       "      <td>0.037128</td>\n",
       "      <td>-0.075268</td>\n",
       "      <td>-0.043568</td>\n",
       "      <td>-0.062431</td>\n",
       "      <td>0.059275</td>\n",
       "      <td>0.047357</td>\n",
       "      <td>0.016749</td>\n",
       "      <td>0.030577</td>\n",
       "      <td>-0.030481</td>\n",
       "      <td>-0.056620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.058635</td>\n",
       "      <td>-0.045142</td>\n",
       "      <td>-0.013223</td>\n",
       "      <td>-0.057510</td>\n",
       "      <td>-0.058827</td>\n",
       "      <td>-0.045073</td>\n",
       "      <td>0.049923</td>\n",
       "      <td>-0.037553</td>\n",
       "      <td>0.048730</td>\n",
       "      <td>0.054082</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018901</td>\n",
       "      <td>-0.065250</td>\n",
       "      <td>-0.055963</td>\n",
       "      <td>-0.034436</td>\n",
       "      <td>0.033379</td>\n",
       "      <td>0.064603</td>\n",
       "      <td>-0.006494</td>\n",
       "      <td>0.065023</td>\n",
       "      <td>-0.055938</td>\n",
       "      <td>-0.057465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.012918</td>\n",
       "      <td>-0.058709</td>\n",
       "      <td>-0.057442</td>\n",
       "      <td>0.022687</td>\n",
       "      <td>-0.030490</td>\n",
       "      <td>0.002568</td>\n",
       "      <td>0.063857</td>\n",
       "      <td>-0.041285</td>\n",
       "      <td>-0.008176</td>\n",
       "      <td>0.017138</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026759</td>\n",
       "      <td>-0.066561</td>\n",
       "      <td>0.032484</td>\n",
       "      <td>0.034660</td>\n",
       "      <td>0.014997</td>\n",
       "      <td>0.047447</td>\n",
       "      <td>0.049137</td>\n",
       "      <td>-0.007857</td>\n",
       "      <td>-0.045889</td>\n",
       "      <td>-0.023475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.039173</td>\n",
       "      <td>-0.034146</td>\n",
       "      <td>-0.020552</td>\n",
       "      <td>0.022493</td>\n",
       "      <td>0.060880</td>\n",
       "      <td>0.061192</td>\n",
       "      <td>-0.044590</td>\n",
       "      <td>0.065717</td>\n",
       "      <td>0.029225</td>\n",
       "      <td>0.043425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.060069</td>\n",
       "      <td>-0.067727</td>\n",
       "      <td>-0.062527</td>\n",
       "      <td>-0.032236</td>\n",
       "      <td>-0.008576</td>\n",
       "      <td>0.056625</td>\n",
       "      <td>-0.028855</td>\n",
       "      <td>-0.061394</td>\n",
       "      <td>-0.031723</td>\n",
       "      <td>-0.027810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2682704</th>\n",
       "      <td>-0.027332</td>\n",
       "      <td>-0.053045</td>\n",
       "      <td>-0.030270</td>\n",
       "      <td>-0.007131</td>\n",
       "      <td>-0.002052</td>\n",
       "      <td>0.044308</td>\n",
       "      <td>-0.051748</td>\n",
       "      <td>0.022303</td>\n",
       "      <td>0.053135</td>\n",
       "      <td>-0.020410</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.050926</td>\n",
       "      <td>-0.060742</td>\n",
       "      <td>-0.057255</td>\n",
       "      <td>-0.040409</td>\n",
       "      <td>0.050371</td>\n",
       "      <td>-0.051289</td>\n",
       "      <td>0.057758</td>\n",
       "      <td>-0.057443</td>\n",
       "      <td>0.032680</td>\n",
       "      <td>-0.051241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2682705</th>\n",
       "      <td>-0.045520</td>\n",
       "      <td>-0.060718</td>\n",
       "      <td>-0.010936</td>\n",
       "      <td>-0.034423</td>\n",
       "      <td>-0.021102</td>\n",
       "      <td>-0.001715</td>\n",
       "      <td>-0.039156</td>\n",
       "      <td>0.009681</td>\n",
       "      <td>0.046584</td>\n",
       "      <td>0.049113</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.023909</td>\n",
       "      <td>-0.062251</td>\n",
       "      <td>-0.052949</td>\n",
       "      <td>-0.048105</td>\n",
       "      <td>0.039565</td>\n",
       "      <td>-0.003266</td>\n",
       "      <td>-0.000487</td>\n",
       "      <td>0.016957</td>\n",
       "      <td>-0.039132</td>\n",
       "      <td>-0.026351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2682706</th>\n",
       "      <td>-0.060206</td>\n",
       "      <td>-0.058392</td>\n",
       "      <td>-0.023982</td>\n",
       "      <td>-0.057334</td>\n",
       "      <td>-0.047456</td>\n",
       "      <td>-0.002678</td>\n",
       "      <td>-0.027173</td>\n",
       "      <td>0.033519</td>\n",
       "      <td>-0.008071</td>\n",
       "      <td>0.060020</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.025248</td>\n",
       "      <td>-0.061354</td>\n",
       "      <td>-0.059058</td>\n",
       "      <td>-0.060890</td>\n",
       "      <td>0.011957</td>\n",
       "      <td>0.057697</td>\n",
       "      <td>0.060536</td>\n",
       "      <td>0.060914</td>\n",
       "      <td>-0.020374</td>\n",
       "      <td>-0.055883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2682707</th>\n",
       "      <td>-0.002958</td>\n",
       "      <td>-0.054142</td>\n",
       "      <td>-0.058888</td>\n",
       "      <td>-0.038984</td>\n",
       "      <td>-0.039324</td>\n",
       "      <td>-0.059528</td>\n",
       "      <td>-0.042302</td>\n",
       "      <td>0.048775</td>\n",
       "      <td>-0.014610</td>\n",
       "      <td>-0.007164</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.038994</td>\n",
       "      <td>-0.061646</td>\n",
       "      <td>-0.047807</td>\n",
       "      <td>-0.056433</td>\n",
       "      <td>-0.060892</td>\n",
       "      <td>0.048175</td>\n",
       "      <td>0.060353</td>\n",
       "      <td>-0.003527</td>\n",
       "      <td>-0.048387</td>\n",
       "      <td>-0.027356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2682708</th>\n",
       "      <td>-0.040311</td>\n",
       "      <td>-0.013653</td>\n",
       "      <td>0.022147</td>\n",
       "      <td>0.040639</td>\n",
       "      <td>-0.049974</td>\n",
       "      <td>-0.060231</td>\n",
       "      <td>-0.029883</td>\n",
       "      <td>0.043004</td>\n",
       "      <td>0.063270</td>\n",
       "      <td>-0.027816</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.041139</td>\n",
       "      <td>-0.064618</td>\n",
       "      <td>-0.033358</td>\n",
       "      <td>-0.044034</td>\n",
       "      <td>-0.002591</td>\n",
       "      <td>0.063870</td>\n",
       "      <td>0.028943</td>\n",
       "      <td>-0.034231</td>\n",
       "      <td>-0.051396</td>\n",
       "      <td>0.021002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2682709 rows × 512 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4         5         6    \\\n",
       "0       -0.059651 -0.058564 -0.043585 -0.055376  0.040285 -0.059395  0.042767   \n",
       "1       -0.020976 -0.016075 -0.021127 -0.066995 -0.012023 -0.006514 -0.045765   \n",
       "2       -0.058635 -0.045142 -0.013223 -0.057510 -0.058827 -0.045073  0.049923   \n",
       "3       -0.012918 -0.058709 -0.057442  0.022687 -0.030490  0.002568  0.063857   \n",
       "4       -0.039173 -0.034146 -0.020552  0.022493  0.060880  0.061192 -0.044590   \n",
       "...           ...       ...       ...       ...       ...       ...       ...   \n",
       "2682704 -0.027332 -0.053045 -0.030270 -0.007131 -0.002052  0.044308 -0.051748   \n",
       "2682705 -0.045520 -0.060718 -0.010936 -0.034423 -0.021102 -0.001715 -0.039156   \n",
       "2682706 -0.060206 -0.058392 -0.023982 -0.057334 -0.047456 -0.002678 -0.027173   \n",
       "2682707 -0.002958 -0.054142 -0.058888 -0.038984 -0.039324 -0.059528 -0.042302   \n",
       "2682708 -0.040311 -0.013653  0.022147  0.040639 -0.049974 -0.060231 -0.029883   \n",
       "\n",
       "              7         8         9    ...       502       503       504  \\\n",
       "0        0.054109 -0.033267  0.060300  ... -0.010115 -0.060441 -0.005488   \n",
       "1       -0.060472  0.070335  0.057117  ...  0.037128 -0.075268 -0.043568   \n",
       "2       -0.037553  0.048730  0.054082  ...  0.018901 -0.065250 -0.055963   \n",
       "3       -0.041285 -0.008176  0.017138  ...  0.026759 -0.066561  0.032484   \n",
       "4        0.065717  0.029225  0.043425  ... -0.060069 -0.067727 -0.062527   \n",
       "...           ...       ...       ...  ...       ...       ...       ...   \n",
       "2682704  0.022303  0.053135 -0.020410  ... -0.050926 -0.060742 -0.057255   \n",
       "2682705  0.009681  0.046584  0.049113  ... -0.023909 -0.062251 -0.052949   \n",
       "2682706  0.033519 -0.008071  0.060020  ... -0.025248 -0.061354 -0.059058   \n",
       "2682707  0.048775 -0.014610 -0.007164  ... -0.038994 -0.061646 -0.047807   \n",
       "2682708  0.043004  0.063270 -0.027816  ... -0.041139 -0.064618 -0.033358   \n",
       "\n",
       "              505       506       507       508       509       510       511  \n",
       "0       -0.058637  0.028976  0.057778 -0.015628  0.060211 -0.057778 -0.060236  \n",
       "1       -0.062431  0.059275  0.047357  0.016749  0.030577 -0.030481 -0.056620  \n",
       "2       -0.034436  0.033379  0.064603 -0.006494  0.065023 -0.055938 -0.057465  \n",
       "3        0.034660  0.014997  0.047447  0.049137 -0.007857 -0.045889 -0.023475  \n",
       "4       -0.032236 -0.008576  0.056625 -0.028855 -0.061394 -0.031723 -0.027810  \n",
       "...           ...       ...       ...       ...       ...       ...       ...  \n",
       "2682704 -0.040409  0.050371 -0.051289  0.057758 -0.057443  0.032680 -0.051241  \n",
       "2682705 -0.048105  0.039565 -0.003266 -0.000487  0.016957 -0.039132 -0.026351  \n",
       "2682706 -0.060890  0.011957  0.057697  0.060536  0.060914 -0.020374 -0.055883  \n",
       "2682707 -0.056433 -0.060892  0.048175  0.060353 -0.003527 -0.048387 -0.027356  \n",
       "2682708 -0.044034 -0.002591  0.063870  0.028943 -0.034231 -0.051396  0.021002  \n",
       "\n",
       "[2682709 rows x 512 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorized_abstracts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42bb0d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vectorized_abstracts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7babd695",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=32)\n",
    "pca_result = pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d1a5d431",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(pca_result).to_csv(\"processed_data/\" + global_dataset + \"_papers_features_vectorized_compressed_32.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dcaa534b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 65202/65202 [00:00<00:00, 576920.42it/s]\n"
     ]
    }
   ],
   "source": [
    "papers_edge_list_indexed = papers_edges.values\n",
    "for i in tqdm(range(len(papers_edge_list_indexed))):\n",
    "    pair = papers_edge_list_indexed[i]\n",
    "    for j in range(len(pair)):\n",
    "        pair[j] = id_to_index_id[pair[j]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d5c6c912",
   "metadata": {},
   "outputs": [],
   "source": [
    "papers_edge_list_indexed_np = pd.DataFrame(papers_edge_list_indexed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0b1c070f",
   "metadata": {},
   "outputs": [],
   "source": [
    "papers_edge_list_indexed_np.to_csv(\"processed_data/\" + global_dataset + \"_papers_edge_list_indexed.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11707464",
   "metadata": {},
   "source": [
    "### Execute after subdataset extraction\n",
    "Journals of papers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3d69a82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'SSORC_CS_10_21_1437_3164_unfiltered' #'SSORC_CS_10_21_3340_16830_115907_primus'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0fc511ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "citation_graph = nx.read_edgelist(\"datasets/\" + dataset_name + \"/\" + dataset_name + \"_\" + \"papers.edgelist\", create_using = nx.DiGraph)\n",
    "\n",
    "nodes = list(citation_graph.nodes())\n",
    "nodes = [int(nodes[i]) for i in range(len(nodes))]\n",
    "\n",
    "papers_features.loc[nodes, :][\"journalName\"].to_frame().to_csv(\"datasets/\" + dataset_name + \"/\" + dataset_name + \"_journals.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
